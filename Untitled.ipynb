{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time \n",
    "import keras.backend as K\n",
    "import keras \n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.losses import mean_absolute_error\n",
    "from keras.layers import Flatten,Dropout,Dense\n",
    "from keras.models import Input,Model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.losses import mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = Input(shape=(224,224,3))\n",
    "positive = Input(shape=(224,224,3))\n",
    "negative = Input(shape=(224,224,3))\n",
    "\n",
    "Inputs = [anchor,positive,negative]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = ResNet50(include_top=True,weights='imagenet',input_tensor=Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = basemodel.layers\n",
    "newlayers = layers[1:]\n",
    "basemodel.layers = newlayers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oanchor = basemodel(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opositive = basemodel(positive)\n",
    "onegarive = basemodel(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a = Input(shape=(280, 256))\n",
    "tweet_b = Input(shape=(280, 256))\n",
    "tweet_c = Input(shape=(280, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "# When we reuse the same layer instance\n",
    "# multiple times, the weights of the layer\n",
    "# are also being reused\n",
    "# (it is effectively *the same* layer)\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "encoded_c = shared_lstm(tweet_c)\n",
    "\n",
    "dense = Dense(1, activation='sigmoid')\n",
    "predictions1 = dense(encoded_a)\n",
    "predictions2 = dense(encoded_b)\n",
    "predictions3 = dense(encoded_c)\n",
    "\n",
    "data_a = np.random.random((10,280,256))\n",
    "data_b = np.random.random((10,280,256))\n",
    "data_c = np.random.random((10,280,256))\n",
    "labels = np.random.random((10))\n",
    "\n",
    "def lossf (true,pred):\n",
    "    print tf.shape(true)\n",
    "    print tf.shape(pred)\n",
    "    return K.sum(true-pred,axis=-1)\n",
    "\n",
    "    \n",
    "model = Model(inputs=[tweet_a, tweet_b, tweet_c], outputs=[predictions1,predictions2,predictions3])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=lossf,#'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([data_a, data_b,data_c], [labels,labels,labels], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict([data_a,data_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model=model,to_file='aaa.png',show_layer_names=True,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D,Dropout,Input,Lambda,GlobalMaxPooling2D\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "image_size = 224\n",
    "embedding_dim = 5\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "A = np.ones([batch_size,embedding_dim])\n",
    "A /= embedding_dim\n",
    "A = K.variable(A)\n",
    "    \n",
    "def fake_loss(X):\n",
    "    item, _,_ = X\n",
    "    # item = X\n",
    "    loss = K.sum(A * item, axis=-1, keepdims=True)\n",
    "    return loss\n",
    "    \n",
    "############## Model ########################### \n",
    "def GetBaseModel():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(embedding_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def GetMyModel(base_model):\n",
    "    input_1 = Input((image_size,image_size,3))\n",
    "    input_2 = Input((image_size,image_size,3))\n",
    "    input_3 = Input((image_size,image_size,3))\n",
    "\n",
    "    r1 = base_model(input_1)\n",
    "    r2 = base_model(input_2)\n",
    "    r3= base_model(input_3)\n",
    "\n",
    "    loss = Lambda(fake_loss)([r1,r2,r3]) \n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000003))\n",
    "    # print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GetMyModel(GetBaseModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model=model,show_layer_names=True,show_shapes=True,to_file='aaaaaa.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {\n",
    "    'input_28':np.random.random((10,224,224,3)),\n",
    "    'input_29':np.random.random((10,224,224,3)),\n",
    "    'input_30':np.random.random((10,224,224,3))\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = model.predict(x=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20432337 0.20000017]\n",
      " [0.21471745 0.19999993]\n",
      " [0.1909476  0.20000005]\n",
      " [0.22964521 0.19999993]\n",
      " [0.22238642 0.19999999]\n",
      " [0.19909978 0.2000001 ]\n",
      " [0.20273677 0.19999993]\n",
      " [0.21264708 0.20000005]\n",
      " [0.17750347 0.2000001 ]\n",
      " [0.20533983 0.19999993]\n",
      " [0.19847883 0.20000017]\n",
      " [0.19501649 0.19999993]\n",
      " [0.18675184 0.19999999]\n",
      " [0.19162099 0.20000005]\n",
      " [0.23120736 0.19999999]\n",
      " [0.16960675 0.19999993]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, GlobalMaxPooling2D, Dropout, Lambda, Merge, concatenate\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "############## Settings ###########################\n",
    "batch_size = 16\n",
    "image_size = 224\n",
    "embedding_dim = 5\n",
    "############## DATA ###########################\n",
    "def GetRandomImage():\n",
    "    return np.random.randint(low=0, high=256, size=[image_size,image_size,3])\n",
    "    \n",
    "def GetTriplet():\n",
    "    a = GetRandomImage()\n",
    "    b = GetRandomImage()\n",
    "    c = GetRandomImage()\n",
    "    return a,b,c\n",
    "\n",
    "def Generate():\n",
    "    while True:\n",
    "        list_a = []\n",
    "        list_b = []\n",
    "        list_c = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            a, b, c = GetTriplet()\n",
    "            list_a.append(a)\n",
    "            list_b.append(b)\n",
    "            list_c.append(c)\n",
    "            \n",
    "        A = preprocess_input(np.array(list_a, dtype='float32'))\n",
    "        B = preprocess_input(np.array(list_b, dtype='float32'))\n",
    "        C = preprocess_input(np.array(list_c, dtype='float32'))\n",
    "        label = np.ones((batch_size,2))\n",
    "        yield [A, B, C], label\n",
    "\n",
    "\n",
    "train_generator = Generate()\n",
    "test_generator = Generate()\n",
    "batch = next(train_generator)\n",
    "       \n",
    "############## LOSS ########################### \n",
    "def identity_loss(y_true, y_pred):\n",
    "    \n",
    "    r = y_true[0] - y_pred[0]\n",
    "    \n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def fake_loss(X):\n",
    "    item1, item2, item3 = X\n",
    "    # item = X\n",
    "    ##loss = K.sum(A * item1, axis=-1, keepdims=True)\n",
    "    loss = K.sum(K.square(item1-item2),axis=-1,keepdims=True)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def Le(X):\n",
    "    a, p, n = X\n",
    "    m = 0.2\n",
    "    loss = K.relu(m + K.sum(K.square(a-p),axis=-1,keepdims=True) - K.sum(K.square(a-n),axis=-1,keepdims=True))\n",
    "    return loss\n",
    "def Ld_1(X):\n",
    "    a, p, n = X\n",
    "    m = 0.2\n",
    "    loss = K.relu(m+ K.sqrt(K.sum(K.square(a),axis=-1,keepdims=True)) - K.sqrt(K.sum(K.square(n),axis=-1,keepdims=True))) \n",
    "    return loss\n",
    "\n",
    "def triplet_loss(y_true,y_pred):\n",
    "    sa = y_true[0]\n",
    "    sp = y_true[1]\n",
    "    sn = y_true[2]\n",
    "    \n",
    "    ld = y_pred[0]\n",
    "    le = y_pred[0]\n",
    "    \n",
    "    return (sn - sa)*ld + le\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "############## Model ########################### \n",
    "def GetBaseModel():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(embedding_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def GetMyModel(base_model):\n",
    "    input_1 = Input((image_size,image_size,3))\n",
    "    input_2 = Input((image_size,image_size,3))\n",
    "    input_3 = Input((image_size,image_size,3))\n",
    "\n",
    "    r1 = base_model(input_1)\n",
    "    r2 = base_model(input_2)\n",
    "    r3= base_model(input_3)\n",
    "\n",
    "    loss_le = Lambda(Le)([r1,r2,r3])\n",
    "    loss_ld1 = Lambda(Ld_1)([r1,r2,r3])\n",
    "    loss = concatenate([loss_le,loss_ld1],axis=-1)\n",
    "    \n",
    "    ##loss_ld1 = Lambda(Ld_1)\n",
    "    \n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000003))\n",
    "    # print(model.summary())\n",
    "    return model\n",
    "\n",
    "base_model = GetBaseModel()\n",
    "model = GetMyModel(base_model)\n",
    "\n",
    "#print(model.predict_on_batch(batch[0]))\n",
    "\n",
    "print(model.predict_on_batch(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  3/100 [..............................] - ETA: 57:55 - loss: 0.3314  "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=5, \n",
    "                    verbose=1, \n",
    "                    workers=4,\n",
    "                    steps_per_epoch=100, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict_on_batch(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.expand_dims(np.ones((9,1)),axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input((image_size,image_size,3))\n",
    "input_2 = Input((image_size,image_size,3))\n",
    "input_3 = Input((image_size,image_size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate,Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = concatenate(inputs=[input_1,input_2,input_3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.ones(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model=model,show_layer_names=True,show_shapes=True,to_file='triplet_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
