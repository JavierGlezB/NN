{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"ResNet50 model definition compatible with TensorFlow's eager execution.\n",
    "\n",
    "Reference [Deep Residual Learning for Image\n",
    "Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "Adapted from tf.keras.applications.ResNet50. A notable difference is that the\n",
    "model here outputs logits while the Keras model outputs probability.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "\n",
    "class _IdentityBlock(tf.keras.Model):\n",
    "  \"\"\"_IdentityBlock is the block that has no conv layer at shortcut.\n",
    "\n",
    "  Args:\n",
    "    kernel_size: the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    data_format: data_format for the input ('channels_first' or\n",
    "      'channels_last').\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, kernel_size, filters, stage, block, data_format):\n",
    "    super(_IdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    bn_axis = 1 if data_format == 'channels_first' else 3\n",
    "\n",
    "    self.conv2a = layers.Conv2D(\n",
    "        filters1, (1, 1), name=conv_name_base + '2a', data_format=data_format)\n",
    "    self.bn2a = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = layers.Conv2D(\n",
    "        filters2,\n",
    "        kernel_size,\n",
    "        padding='same',\n",
    "        data_format=data_format,\n",
    "        name=conv_name_base + '2b')\n",
    "    self.bn2b = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = layers.Conv2D(\n",
    "        filters3, (1, 1), name=conv_name_base + '2c', data_format=data_format)\n",
    "    self.bn2c = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '2c')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "class _ConvBlock(tf.keras.Model):\n",
    "  \"\"\"_ConvBlock is the block that has a conv layer at shortcut.\n",
    "\n",
    "  Args:\n",
    "      kernel_size: the kernel size of middle conv layer at main path\n",
    "      filters: list of integers, the filters of 3 conv layer at main path\n",
    "      stage: integer, current stage label, used for generating layer names\n",
    "      block: 'a','b'..., current block label, used for generating layer names\n",
    "      data_format: data_format for the input ('channels_first' or\n",
    "        'channels_last').\n",
    "      strides: strides for the convolution. Note that from stage 3, the first\n",
    "       conv layer at main path is with strides=(2,2), and the shortcut should\n",
    "       have strides=(2,2) as well.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               data_format,\n",
    "               strides=(2, 2)):\n",
    "    super(_ConvBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    bn_axis = 1 if data_format == 'channels_first' else 3\n",
    "\n",
    "    self.conv2a = layers.Conv2D(\n",
    "        filters1, (1, 1),\n",
    "        strides=strides,\n",
    "        name=conv_name_base + '2a',\n",
    "        data_format=data_format)\n",
    "    self.bn2a = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '2a')\n",
    "\n",
    "    self.conv2b = layers.Conv2D(\n",
    "        filters2,\n",
    "        kernel_size,\n",
    "        padding='same',\n",
    "        name=conv_name_base + '2b',\n",
    "        data_format=data_format)\n",
    "    self.bn2b = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '2b')\n",
    "\n",
    "    self.conv2c = layers.Conv2D(\n",
    "        filters3, (1, 1), name=conv_name_base + '2c', data_format=data_format)\n",
    "    self.bn2c = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '2c')\n",
    "\n",
    "    self.conv_shortcut = layers.Conv2D(\n",
    "        filters3, (1, 1),\n",
    "        strides=strides,\n",
    "        name=conv_name_base + '1',\n",
    "        data_format=data_format)\n",
    "    self.bn_shortcut = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    shortcut = self.conv_shortcut(input_tensor)\n",
    "    shortcut = self.bn_shortcut(shortcut, training=training)\n",
    "\n",
    "    x += shortcut\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "# pylint: disable=not-callable\n",
    "class ResNet50(tf.keras.Model):\n",
    "  \"\"\"Instantiates the ResNet50 architecture.\n",
    "\n",
    "  Args:\n",
    "    data_format: format for the image. Either 'channels_first' or\n",
    "      'channels_last'.  'channels_first' is typically faster on GPUs while\n",
    "      'channels_last' is typically faster on CPUs. See\n",
    "      https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "    name: Prefix applied to names of variables created in the model.\n",
    "    trainable: Is the model trainable? If true, performs backward\n",
    "        and optimization after call() method.\n",
    "    include_top: whether to include the fully-connected layer at the top of the\n",
    "      network.\n",
    "    pooling: Optional pooling mode for feature extraction when `include_top`\n",
    "      is `False`.\n",
    "      - `None` means that the output of the model will be the 4D tensor\n",
    "          output of the last convolutional layer.\n",
    "      - `avg` means that global average pooling will be applied to the output of\n",
    "          the last convolutional layer, and thus the output of the model will be\n",
    "          a 2D tensor.\n",
    "      - `max` means that global max pooling will be applied.\n",
    "    classes: optional number of classes to classify images into, only to be\n",
    "      specified if `include_top` is True.\n",
    "\n",
    "  Raises:\n",
    "      ValueError: in case of invalid argument for data_format.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               data_format = 'channels_first',\n",
    "               name='xvr',\n",
    "               trainable=True,\n",
    "               include_top=False,\n",
    "               pooling='max',\n",
    "               classes=1000):\n",
    "    super(ResNet50, self).__init__(name=name)\n",
    "\n",
    "    valid_channel_values = ('channels_first', 'channels_last')\n",
    "    if data_format not in valid_channel_values:\n",
    "      raise ValueError('Unknown data_format: %s. Valid values: %s' %\n",
    "                       (data_format, valid_channel_values))\n",
    "    self.include_top = include_top\n",
    "\n",
    "    def conv_block(filters, stage, block, strides=(2, 2)):\n",
    "      return _ConvBlock(\n",
    "          3,\n",
    "          filters,\n",
    "          stage=stage,\n",
    "          block=block,\n",
    "          data_format=data_format,\n",
    "          strides=strides)\n",
    "\n",
    "    def id_block(filters, stage, block):\n",
    "      return _IdentityBlock(\n",
    "          3, filters, stage=stage, block=block, data_format=data_format)\n",
    "    self.conv1 = layers.Conv2D(\n",
    "        64, (7, 7),\n",
    "        strides=(2, 2),\n",
    "        data_format=data_format,\n",
    "        padding='same',\n",
    "        name='conv1')\n",
    "    bn_axis = 1 if data_format == 'channels_first' else 3\n",
    "    self.bn_conv1 = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')\n",
    "    self.max_pool = layers.MaxPooling2D(\n",
    "        (3, 3), strides=(2, 2), data_format=data_format)\n",
    "\n",
    "    self.l2a = conv_block([64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    self.l2b = id_block([64, 64, 256], stage=2, block='b')\n",
    "    self.l2c = id_block([64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    self.l3a = conv_block([128, 128, 512], stage=3, block='a')\n",
    "    self.l3b = id_block([128, 128, 512], stage=3, block='b')\n",
    "    self.l3c = id_block([128, 128, 512], stage=3, block='c')\n",
    "    self.l3d = id_block([128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    self.l4a = conv_block([256, 256, 1024], stage=4, block='a')\n",
    "    self.l4b = id_block([256, 256, 1024], stage=4, block='b')\n",
    "    self.l4c = id_block([256, 256, 1024], stage=4, block='c')\n",
    "    self.l4d = id_block([256, 256, 1024], stage=4, block='d')\n",
    "    self.l4e = id_block([256, 256, 1024], stage=4, block='e')\n",
    "    self.l4f = id_block([256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    self.l5a = conv_block([512, 512, 2048], stage=5, block='a')\n",
    "    self.l5b = id_block([512, 512, 2048], stage=5, block='b')\n",
    "    self.l5c = id_block([512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    self.avg_pool = layers.AveragePooling2D(\n",
    "        (7, 7), strides=(7, 7), data_format=data_format)\n",
    "\n",
    "    if self.include_top:\n",
    "      self.flatten = layers.Flatten()\n",
    "      self.fc1000 = layers.Dense(classes, name='fc1000')\n",
    "    else:\n",
    "      reduction_indices = [1, 2] if data_format == 'channels_last' else [2, 3]\n",
    "      reduction_indices = tf.constant(reduction_indices)\n",
    "      if pooling == 'avg':\n",
    "        self.global_pooling = functools.partial(\n",
    "            tf.reduce_mean,\n",
    "            reduction_indices=reduction_indices,\n",
    "            keep_dims=False)\n",
    "      elif pooling == 'max':\n",
    "        self.global_pooling = functools.partial(\n",
    "            tf.reduce_max, reduction_indices=reduction_indices, keep_dims=False)\n",
    "      else:\n",
    "        self.global_pooling = None\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    x = self.conv1(inputs)\n",
    "    x = self.bn_conv1(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.max_pool(x)\n",
    "\n",
    "    x = self.l2a(x, training=training)\n",
    "    x = self.l2b(x, training=training)\n",
    "    x = self.l2c(x, training=training)\n",
    "\n",
    "    x = self.l3a(x, training=training)\n",
    "    x = self.l3b(x, training=training)\n",
    "    x = self.l3c(x, training=training)\n",
    "    x = self.l3d(x, training=training)\n",
    "\n",
    "    x = self.l4a(x, training=training)\n",
    "    x = self.l4b(x, training=training)\n",
    "    x = self.l4c(x, training=training)\n",
    "    x = self.l4d(x, training=training)\n",
    "    x = self.l4e(x, training=training)\n",
    "    x = self.l4f(x, training=training)\n",
    "\n",
    "    x = self.l5a(x, training=training)\n",
    "    x = self.l5b(x, training=training)\n",
    "    x = self.l5c(x, training=training)\n",
    "\n",
    "    x = self.avg_pool(x)\n",
    "\n",
    "    if self.include_top:\n",
    "      return self.fc1000(self.flatten(x))\n",
    "    elif self.global_pooling:\n",
    "      return self.global_pooling(x)\n",
    "    else:\n",
    "      return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
