{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capptu Image Aesthetics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Triplet Model by XVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Model)              (None, 1000)         25636712    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "[[0.20382683 0.20000005]\n",
      " [0.19346836 0.19999993]\n",
      " [0.20427728 0.19999999]\n",
      " [0.19226101 0.2000001 ]\n",
      " [0.18193412 0.19999993]\n",
      " [0.20306331 0.19999999]\n",
      " [0.20816025 0.20000023]\n",
      " [0.20531583 0.19999999]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, GlobalMaxPooling2D, Dropout, Lambda, Merge, concatenate\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import tensorflow as tf\n",
    "############## Settings ###########################\n",
    "batch_size = 8\n",
    "image_size = 224\n",
    "\n",
    "embedding_dim = 1000\n",
    "############## DATA ###########################\n",
    "def GetRandomImage():\n",
    "    return np.random.randint(low=0, high=256, size=[image_size,image_size,3])\n",
    "    \n",
    "def GetTriplet():\n",
    "    a = GetRandomImage()\n",
    "    b = GetRandomImage()\n",
    "    c = GetRandomImage()\n",
    "    return a,b,c\n",
    "\n",
    "def Generate():\n",
    "    while True:\n",
    "        list_a = []\n",
    "        list_b = []\n",
    "        list_c = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            a, b, c = GetTriplet()\n",
    "            list_a.append(a)\n",
    "            list_b.append(b)\n",
    "            list_c.append(c)\n",
    "            \n",
    "        A = preprocess_input(np.array(list_a, dtype='float32'))\n",
    "        B = preprocess_input(np.array(list_b, dtype='float32'))\n",
    "        C = preprocess_input(np.array(list_c, dtype='float32'))\n",
    "        label = np.ones((batch_size,2))\n",
    "        yield [A, B, C], label\n",
    "\n",
    "\n",
    "train_generator = Generate()\n",
    "test_generator = Generate()\n",
    "batch = next(train_generator)\n",
    "       \n",
    "############## LOSS ########################### \n",
    "def identity_loss(y_true, y_pred):\n",
    "    \n",
    "    r = y_true[0] - y_pred[0]\n",
    "    \n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "def fake_loss(X):\n",
    "    item1, item2, item3 = X\n",
    "    # item = X\n",
    "    ##loss = K.sum(A * item1, axis=-1, keepdims=True)\n",
    "    loss = K.sum(K.square(item1-item2),axis=-1,keepdims=True)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def Le(X):\n",
    "    a, p, n = X\n",
    "    m = 0.2\n",
    "    loss = K.relu(m + K.sum(K.square(a-p),axis=-1,keepdims=True) - K.sum(K.square(a-n),axis=-1,keepdims=True))\n",
    "    return loss\n",
    "def Ld_1(X):\n",
    "    a, p, n = X\n",
    "    m = 0.2\n",
    "    loss = K.relu(m+ K.sqrt(K.sum(K.square(a),axis=-1,keepdims=True)) - K.sqrt(K.sum(K.square(n),axis=-1,keepdims=True))) \n",
    "    return loss\n",
    "\n",
    "def triplet_loss(y_true,y_pred):\n",
    "    sa = y_true[0]\n",
    "    sp = y_true[1]\n",
    "    sn = y_true[2]\n",
    "    \n",
    "    ld = y_pred[0]\n",
    "    le = y_pred[0]\n",
    "    \n",
    "    return (sn - sa)*ld + le\n",
    "\n",
    "############## Model ########################### \n",
    "def GetBaseModel():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(embedding_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def GetMyModel(base_model):\n",
    "    input_1 = Input((image_size,image_size,3))\n",
    "    input_2 = Input((image_size,image_size,3))\n",
    "    input_3 = Input((image_size,image_size,3))\n",
    "\n",
    "    r1 = base_model(input_1)\n",
    "    r2 = base_model(input_2)\n",
    "    r3= base_model(input_3)\n",
    "\n",
    "    loss_le = Lambda(Le)([r1,r2,r3])\n",
    "    loss_ld1 = Lambda(Ld_1)([r1,r2,r3])\n",
    "    loss = concatenate([loss_le,loss_ld1],axis=-1)\n",
    "    \n",
    "    ##loss_ld1 = Lambda(Ld_1)\n",
    "    \n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000003))\n",
    "    return model\n",
    "\n",
    "base_model = GetBaseModel()\n",
    "model = GetMyModel(base_model)\n",
    "model.summary()\n",
    "\n",
    "#print(model.predict_on_batch(batch[0]))\n",
    "print(model.predict_on_batch(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 44s 441ms/step - loss: 0.1986 - val_loss: 0.2000\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.2016 - val_loss: 0.2000\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 0.1982 - val_loss: 0.2000\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.2014 - val_loss: 0.2000\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.2016 - val_loss: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe598e78990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=5, \n",
    "                    verbose=1, \n",
    "                    workers=4,\n",
    "                    steps_per_epoch=100, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Loss Model Capptu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time \n",
    "import keras.backend as K\n",
    "import keras \n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.losses import mean_absolute_error, categorical_crossentropy,mean_absolute_error\n",
    "from keras.layers import Flatten, Dropout, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Lambda, concatenate\n",
    "from keras.models import Input,Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_e = 0.2\n",
    "m_d = 0.3\n",
    "\n",
    "TRAINING_SIZE = 100000\n",
    "TESTING_SIZE = 2000\n",
    "VALIDATION_SIZE = 2000\n",
    "\n",
    "TOTAL_IMAGES = 180000\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TRIPLET_INDEX = 0\n",
    "\n",
    "ENCODINGS_DIM = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arod = h5py.File('./AROD_HDF/AROD.hdf','r')\n",
    "triplets = pd.read_csv('./triplets.csv').get_values()[0:TRAINING_SIZE]\n",
    "training_set = triplets[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet():\n",
    "    global TRIPLET_INDEX\n",
    "    triplet = training_set[TRIPLET_INDEX]\n",
    "    \n",
    "    a = arod['IMAGES'][triplet[0]]\n",
    "    p = arod['IMAGES'][triplet[1]]\n",
    "    n = arod['IMAGES'][triplet[2]]\n",
    "    \n",
    "    sa = arod['SCORES'][triplet[0]][0]        \n",
    "    sp = arod['SCORES'][triplet[1]][0]        \n",
    "    sn = arod['SCORES'][triplet[2]][0]        \n",
    "    TRIPLET_INDEX = TRIPLET_INDEX + 1\n",
    "    return a, p, n, sa, sp, sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, p, n, sa, sp, sn = get_triplet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate():\n",
    "    while True:\n",
    "        list_a = []\n",
    "        list_p = []\n",
    "        list_n = []\n",
    "        label = []\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "            a, p, n, sa, sp, sn = get_triplet()\n",
    "            list_a.append(a)\n",
    "            list_p.append(p)\n",
    "            list_n.append(n)\n",
    "            label.append([sa,sn])\n",
    "            \n",
    "        A = preprocess_input(np.array(list_a, dtype = 'float32'))\n",
    "        B = preprocess_input(np.array(list_p, dtype = 'float32'))\n",
    "        C = preprocess_input(np.array(list_n, dtype = 'float32'))\n",
    "        label = np.array(label,dtype = 'float32')\n",
    "        yield [A, B, C], label\n",
    "        #return [A,B,C], label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$L_e (a,p,n) = [m_e + |\\Phi_a - \\Phi_p|^2  - |\\Phi_a - \\Phi_n|^2 ]$ \n",
    "\n",
    "$L_d (a,p,n) = sign (s(n) - s(a) )  [m_d + |\\Phi_a - \\Phi_n| ]  $ \n",
    "\n",
    "$Loss = L_d + L_e$\n",
    "\n",
    "Where :\n",
    "\n",
    "$\\Phi_i:$ Encodings of $ith$ Image\n",
    "\n",
    "$m_d, m_e:$ Margins to avoid Trivial loss response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = Generate()\n",
    "batch = next(train_generator)\n",
    "############## LOSS Function ########################### \n",
    "def identity_loss(y_true, y_pred):\n",
    "    r = y_true[0] - y_pred[0]\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "\n",
    "def Le(X):\n",
    "    a, p, n = X\n",
    "    m = 0.2\n",
    "    loss = K.relu(m + K.sum(K.square(a-p),axis=-1,keepdims=True) - K.sum(K.square(a-n),axis=-1,keepdims=True))\n",
    "    return loss\n",
    "def Ld_1(X):\n",
    "    a, p, n = X\n",
    "    m = 0.2\n",
    "    loss = K.relu(m+ K.sqrt(K.sum(K.square(a),axis=-1,keepdims=True)) - K.sqrt(K.sum(K.square(n),axis=-1,keepdims=True)))\n",
    "    return loss\n",
    "\n",
    "def triplet_loss(y_true,y_pred):\n",
    "    sa = y_true[0]\n",
    "    sp = y_true[1]\n",
    "    sn = y_true[2]\n",
    "    \n",
    "    ld = y_pred[0]\n",
    "    le = y_pred[0]\n",
    "    \n",
    "    return (sn - sa)*ld + le\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net model \n",
    "<img src=\"./Capptu model Resnet50_tripletloss.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Model)              (None, 1000)         25636712    input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "[[0.21541226 0.20000005]\n",
      " [0.28599072 0.19999993]\n",
      " [0.11459875 0.2000001 ]\n",
      " [0.         0.2000001 ]\n",
      " [0.241305   0.20000005]\n",
      " [0.26678467 0.2000001 ]\n",
      " [0.09247947 0.19999999]\n",
      " [0.25996673 0.19999999]]\n"
     ]
    }
   ],
   "source": [
    "############## Model ########################### \n",
    "def GetBaseModel():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(ENCODINGS_DIM)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def GetModel(base_model):\n",
    "    input_1 = Input((IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "    input_2 = Input((IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "    input_3 = Input((IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "    r1 = base_model(input_1)\n",
    "    r2 = base_model(input_2)\n",
    "    r3= base_model(input_3)\n",
    "\n",
    "    loss_le = Lambda(Le)([r1,r2,r3])\n",
    "    loss_ld1 = Lambda(Ld_1)([r1,r2,r3])\n",
    "    loss = concatenate([loss_le,loss_ld1],axis=-1)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000003))\n",
    "    return model\n",
    "base_model = GetBaseModel()\n",
    "model = GetModel(base_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.2027\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 0.2007\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 0.2024\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 0.1980\n",
      "Epoch 5/5\n",
      "  7/100 [=>............................] - ETA: 32s - loss: 0.2008"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    epochs=5, \n",
    "                    verbose=1, \n",
    "                    workers=4,\n",
    "                    steps_per_epoch=100, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
